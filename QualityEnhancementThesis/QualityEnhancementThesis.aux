\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{gehlenborg2010visualization}
\citation{brazma2001minimum}
\citation{cottrell1999probability}
\citation{dettmer2007mass}
\citation{capitani2017nuclear}
\citation{liu2012data}
\citation{sittig2008grand}
\citation{magni1990chronic}
\citation{gehlenborg2010visualization}
\citation{bertolazzi2008logic}
\citation{piatetsky2003microarray}
\citation{lommen2009metalign}
\citation{holzinger2014knowledge}
\citation{wilkins2009proteomics}
\citation{teodoro2009biomedical}
\citation{doi:10.1093/nar/gkm1037}
\citation{sturn2002genesis}
\citation{karnovsky2011metscape}
\citation{tabas2012genecodis3}
\citation{faul2007g}
\citation{dracopoli1991ceph}
\citation{goldberg2008analysis}
\citation{stibor2005negative}
\citation{chandola2009anomaly}
\citation{roberts2000extreme}
\citation{donders2006gentle}
\citation{cartwright2003dealing}
\citation{haukoos2007advanced}
\citation{kan1986short}
\citation{diaconis1983computer}
\citation{cestnikkononenkoj}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\newlabel{sec:Introduction}{{1}{2}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}{section.2}}
\newlabel{sec:Background}{{2}{2}{Background}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Datasets}{2}{subsection.2.1}}
\newlabel{subsec:Datasets}{{2.1}{2}{Datasets}{subsection.2.1}{}}
\citation{murtaugh1994primary}
\citation{fernandes2017transfer}
\citation{patrician2002multiple}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces A schematic overview of the four datasets\relax }}{3}{table.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:Datasets}{{1}{3}{A schematic overview of the four datasets\relax }{table.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Missing Values}{3}{subsection.2.2}}
\newlabel{subsec:MissingValues}{{2.2}{3}{Missing Values}{subsection.2.2}{}}
\citation{donders2006gentle}
\citation{cartwright2003dealing}
\citation{haukoos2007advanced}
\citation{donders2006gentle}
\citation{haukoos2007advanced}
\citation{cartwright2003dealing}
\citation{donders2006gentle}
\citation{cartwright2003dealing}
\citation{haukoos2007advanced}
\citation{haukoos2007advanced}
\citation{donders2006gentle}
\citation{haukoos2007advanced}
\citation{donders2006gentle}
\citation{cartwright2003dealing}
\citation{haukoos2007advanced}
\citation{donders2006gentle}
\citation{patrician2002multiple}
\citation{sterne2009multiple}
\citation{myrtveit2001analyzing}
\citation{haukoos2007advanced}
\citation{patrician2002multiple}
\citation{myrtveit2001analyzing}
\citation{donders2006gentle}
\citation{cartwright2003dealing}
\citation{haukoos2007advanced}
\citation{donders2006gentle}
\citation{patrician2002multiple}
\citation{myrtveit2001analyzing}
\citation{haukoos2007advanced}
\citation{donders2006gentle}
\citation{patrician2002multiple}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}List Deletion}{5}{subsubsection.2.2.1}}
\newlabel{subsec:ListDeletion}{{2.2.1}{5}{List Deletion}{subsubsection.2.2.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Complete Case Analysis\relax }}{5}{algorithm.1}}
\newlabel{alg:CCA}{{1}{5}{Complete Case Analysis\relax }{algorithm.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Available Case Analysis\relax }}{5}{algorithm.2}}
\newlabel{alg:ACA}{{2}{5}{Available Case Analysis\relax }{algorithm.2}{}}
\citation{cartwright2003dealing}
\citation{haukoos2007advanced}
\citation{myrtveit2001analyzing}
\citation{donders2006gentle}
\citation{haukoos2007advanced}
\citation{donders2006gentle}
\citation{myrtveit2001analyzing}
\citation{pedersen2017missing}
\citation{donders2006gentle}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Weighted Case Analysis\relax }}{6}{algorithm.3}}
\newlabel{alg:WCA}{{3}{6}{Weighted Case Analysis\relax }{algorithm.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Single Imputation}{6}{subsubsection.2.2.2}}
\newlabel{subsec:SingleImputation}{{2.2.2}{6}{Single Imputation}{subsubsection.2.2.2}{}}
\citation{haukoos2007advanced}
\citation{myrtveit2001analyzing}
\citation{cartwright2003dealing}
\citation{donders2006gentle}
\citation{pedersen2017missing}
\citation{myrtveit2001analyzing}
\citation{cartwright2003dealing}
\citation{haukoos2007advanced}
\citation{haukoos2007advanced}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Missing Indicator Imputation\relax }}{7}{algorithm.4}}
\newlabel{alg:MissingIndicatorImputation}{{4}{7}{Missing Indicator Imputation\relax }{algorithm.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Mean Imputation\relax }}{7}{algorithm.5}}
\newlabel{alg:MeanImputation}{{5}{7}{Mean Imputation\relax }{algorithm.5}{}}
\citation{raghunathan2001multivariate}
\citation{donders2006gentle}
\citation{myrtveit2001analyzing}
\citation{cartwright2003dealing}
\citation{donders2006gentle}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Hot Deck Imputation\relax }}{8}{algorithm.6}}
\newlabel{alg:HotDeckImputation}{{6}{8}{Hot Deck Imputation\relax }{algorithm.6}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces Multivariate Regression Imputation\relax }}{8}{algorithm.7}}
\newlabel{alg:RegressionImputation}{{7}{8}{Multivariate Regression Imputation\relax }{algorithm.7}{}}
\citation{pedersen2017missing}
\citation{haukoos2007advanced}
\citation{haukoos2007advanced}
\citation{cartwright2003dealing}
\citation{donders2006gentle}
\@writefile{loa}{\contentsline {algorithm}{\numberline {8}{\ignorespaces k Nearest Neighbour Imputation\relax }}{9}{algorithm.8}}
\newlabel{alg:kNNImputation}{{8}{9}{k Nearest Neighbour Imputation\relax }{algorithm.8}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {9}{\ignorespaces k Nearest Neighbour Imputation\relax }}{9}{algorithm.9}}
\newlabel{alg:WorstCaseImputation}{{9}{9}{k Nearest Neighbour Imputation\relax }{algorithm.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Multiple Imputation}{9}{subsubsection.2.2.3}}
\newlabel{subsec:MultipleImputation}{{2.2.3}{9}{Multiple Imputation}{subsubsection.2.2.3}{}}
\citation{chevret2015multiple}
\citation{rubin1976inference}
\citation{chevret2015multiple}
\citation{rubin1976inference}
\citation{pedersen2017missing}
\citation{white2011multiple}
\citation{donders2006gentle}
\citation{he2010multiple}
\citation{van2007multiple}
\citation{pedersen2017missing}
\citation{van1999multiple}
\citation{van2006imputation}
\citation{azur2011multiple}
\citation{royston2004multiple}
\citation{martin2018impact}
\citation{raghunathan2001multivariate}
\citation{white2011multiple}
\citation{donders2006gentle}
\citation{van2006imputation}
\citation{van2006imputation}
\citation{pedersen2017missing}
\citation{pedersen2017missing}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An graphical layout of multiple imputation. At the start a dataset with missing values is present. Missing values are imputed $m$ times to create $m$ imputed datasets. The $m$ complete datasets are all analysed for $m$ different sets of estimates. These results are then pooled into one complete set of estimates.\cite  {chevret2015multiple, rubin1976inference}\relax }}{10}{figure.caption.3}}
\newlabel{fig:MultipleImputationLayout}{{1}{10}{An graphical layout of multiple imputation. At the start a dataset with missing values is present. Missing values are imputed $m$ times to create $m$ imputed datasets. The $m$ complete datasets are all analysed for $m$ different sets of estimates. These results are then pooled into one complete set of estimates.\cite {chevret2015multiple, rubin1976inference}\relax }{figure.caption.3}{}}
\citation{horton2001multiple}
\citation{allison2000multiple}
\citation{royston2011multiple}
\citation{azur2011multiple}
\citation{royston2004multiple}
\citation{he2010multiple}
\citation{azur2011multiple}
\citation{azur2011multiple}
\citation{royston2004multiple}
\citation{pedregosa2011scikit}
\citation{walt2011numpy}
\@writefile{toc}{\contentsline {section}{\numberline {3}Hypotheses}{11}{section.3}}
\newlabel{sec:Hypothesis}{{3}{11}{Hypotheses}{section.3}{}}
\citation{heiberger2004statistical}
\citation{brown1974robust}
\citation{satorra2001scaled}
\citation{satorra2001scaled}
\citation{draper2014applied}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methods}{12}{section.4}}
\newlabel{sec:Methods}{{4}{12}{Methods}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Bias Evaluation}{12}{subsection.4.1}}
\newlabel{subsec:BiasEvaluation}{{4.1}{12}{Bias Evaluation}{subsection.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The three different aspects of the bias evaluation. Four different datasets are used. Two tests are done per feature type, to test hypothesis H0 and seven missing value handling algorithms are implemented to be tested.\relax }}{13}{table.caption.4}}
\newlabel{tab:BiasEvaluationTable}{{2}{13}{The three different aspects of the bias evaluation. Four different datasets are used. Two tests are done per feature type, to test hypothesis H0 and seven missing value handling algorithms are implemented to be tested.\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Quality Evaluation}{13}{subsection.4.2}}
\newlabel{subsec:QualityEvaluation}{{4.2}{13}{Quality Evaluation}{subsection.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces All tested missing value handling methods and possible parameters used during testing\relax }}{14}{table.caption.5}}
\newlabel{tab:MethodsExplanation}{{3}{14}{All tested missing value handling methods and possible parameters used during testing\relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{14}{section.5}}
\newlabel{sec:Results}{{5}{14}{Results}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Bias Evaluation Results}{14}{subsection.5.1}}
\newlabel{subsec:BiasEvaluationResults}{{5.1}{14}{Bias Evaluation Results}{subsection.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Testing for the heart attack data set whether the type of missing values can be represented by the remaining values. This is done by comparing distributions between the old and new data after CCA and WCA. For nominal values, two tests were used, an independent t-test for equality of mean and a Levene's test with the median in brackets to test equality of variance. For ordinal and categorical features the medians and modes where compared respectively as well as a chi squared test in brackets for equality of distribution. P-values lower than $p < 0.05$ are marked red for failure of representation, p-values higher than $p > 0.05$ are marked green for correctly being represented. If at least one feature is not represented after CCA, the missing values cannot be MCAR. If at least one feature is not represented after WCA, the pseudo-randomness cannot be corrected by only using weights for other values.\relax }}{15}{table.caption.6}}
\newlabel{tab:LDHeartAttack}{{4}{15}{Testing for the heart attack data set whether the type of missing values can be represented by the remaining values. This is done by comparing distributions between the old and new data after CCA and WCA. For nominal values, two tests were used, an independent t-test for equality of mean and a Levene's test with the median in brackets to test equality of variance. For ordinal and categorical features the medians and modes where compared respectively as well as a chi squared test in brackets for equality of distribution. P-values lower than $p < 0.05$ are marked red for failure of representation, p-values higher than $p > 0.05$ are marked green for correctly being represented. If at least one feature is not represented after CCA, the missing values cannot be MCAR. If at least one feature is not represented after WCA, the pseudo-randomness cannot be corrected by only using weights for other values.\relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Testing for the heart attack data set if certain types of imputation create a vastly different distribution for features with missing values. The imputation values are generated with mean imputation, hot deck imputation, k-Nearest Neighbour imputation ($k = 3$), regression imputation and MICE (number of cycles is $s = 5$). For nominal values, two tests were used, an independent t-test for equality of mean and a Levene's test with the median in brackets to test equality of variance. For ordinal and categorical features the medians and modes where checked respectively to be similar as well as a chi squared test in brackets fro equality of distribution. P-values lower than $p < 0.05$ are marked red for failure of representation, p-values close to $p > 0.05$ are marked green for correctly being represented.\relax }}{16}{table.caption.8}}
\newlabel{tab:ImputationHeartAttack}{{6}{16}{Testing for the heart attack data set if certain types of imputation create a vastly different distribution for features with missing values. The imputation values are generated with mean imputation, hot deck imputation, k-Nearest Neighbour imputation ($k = 3$), regression imputation and MICE (number of cycles is $s = 5$). For nominal values, two tests were used, an independent t-test for equality of mean and a Levene's test with the median in brackets to test equality of variance. For ordinal and categorical features the medians and modes where checked respectively to be similar as well as a chi squared test in brackets fro equality of distribution. P-values lower than $p < 0.05$ are marked red for failure of representation, p-values close to $p > 0.05$ are marked green for correctly being represented.\relax }{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces A table showing the number of samples that remained after performing CCA.\relax }}{16}{table.caption.7}}
\newlabel{tab:CCARemainingSamples}{{5}{16}{A table showing the number of samples that remained after performing CCA.\relax }{table.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plots showing the probability of the mean of the old and new distribution originating from the same distribution. On the x-axis the percentage of missing values is given for a feature and on the y-axis the p-value of the probability. For every missing value algorithm also a linear fit is made to show the trend of the scatter plot.\relax }}{17}{figure.caption.9}}
\newlabel{fig:PMeanFits}{{2}{17}{Plots showing the probability of the mean of the old and new distribution originating from the same distribution. On the x-axis the percentage of missing values is given for a feature and on the y-axis the p-value of the probability. For every missing value algorithm also a linear fit is made to show the trend of the scatter plot.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Plots showing the probability of the variance of the old and new distribution originating from the same distribution. On the x-axis the percentage of missing values is given for a feature and on the y-axis the p-value of the probability. For every missing value algorithm also a linear fit is made to show the trend of the scatter plot.\relax }}{18}{figure.caption.10}}
\newlabel{fig:PVarianceFits}{{3}{18}{Plots showing the probability of the variance of the old and new distribution originating from the same distribution. On the x-axis the percentage of missing values is given for a feature and on the y-axis the p-value of the probability. For every missing value algorithm also a linear fit is made to show the trend of the scatter plot.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Plots showing the probability of the mean of the old and new distribution originating from the same distribution. On the x-axis the percentage of missing values is given for a feature and on the y-axis the p-value of the probability. For every missing value algorithm also a linear fit is made to show the trend of the scatter plot.\relax }}{19}{figure.caption.11}}
\newlabel{fig:PMeanFitsACA}{{4}{19}{Plots showing the probability of the mean of the old and new distribution originating from the same distribution. On the x-axis the percentage of missing values is given for a feature and on the y-axis the p-value of the probability. For every missing value algorithm also a linear fit is made to show the trend of the scatter plot.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Plots showing the probability of the variance of the old and new distribution originating from the same distribution. Features with more than 15\% missing values were removed before missing value handling was initiated. On the x-axis the percentage of missing values is given for a feature and on the y-axis the p-value of the probability. For every missing value algorithm also a linear fit is made to show the trend of the scatter plot.\relax }}{20}{figure.caption.12}}
\newlabel{fig:PVarianceFitsACA}{{5}{20}{Plots showing the probability of the variance of the old and new distribution originating from the same distribution. Features with more than 15\% missing values were removed before missing value handling was initiated. On the x-axis the percentage of missing values is given for a feature and on the y-axis the p-value of the probability. For every missing value algorithm also a linear fit is made to show the trend of the scatter plot.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Quality Evaluation}{21}{subsection.5.2}}
\newlabel{subsec:QualityEvaluationResults}{{5.2}{21}{Quality Evaluation}{subsection.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A plot showing the average accuracy over for the datasets classified after using a missing value handling algorithm. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }}{22}{figure.caption.13}}
\newlabel{fig:EvalAvgAcc}{{6}{22}{A plot showing the average accuracy over for the datasets classified after using a missing value handling algorithm. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A plot showing the average accuracy over for the datasets classified after using a missing value handling algorithm and after removing all features with more than 15\% missing values. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }}{23}{figure.caption.14}}
\newlabel{fig:EvalAvgAccExtraACA}{{7}{23}{A plot showing the average accuracy over for the datasets classified after using a missing value handling algorithm and after removing all features with more than 15\% missing values. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A plot showing the F1-score over for the datasets classified after using a missing value handling algorithm. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }}{24}{figure.caption.15}}
\newlabel{fig:EvalAvgF1}{{8}{24}{A plot showing the F1-score over for the datasets classified after using a missing value handling algorithm. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }{figure.caption.15}{}}
\bibdata{../References/Citings}
\bibcite{gehlenborg2010visualization}{1}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces The classification results of the datasets and the average after removing all features with missing values, as well as the best results after handling missing values.\relax }}{25}{table.caption.16}}
\newlabel{tab:ClassResults}{{7}{25}{The classification results of the datasets and the average after removing all features with missing values, as well as the best results after handling missing values.\relax }{table.caption.16}{}}
\bibcite{brazma2001minimum}{2}
\bibcite{cottrell1999probability}{3}
\bibcite{dettmer2007mass}{4}
\bibcite{capitani2017nuclear}{5}
\bibcite{liu2012data}{6}
\bibcite{sittig2008grand}{7}
\bibcite{magni1990chronic}{8}
\bibcite{bertolazzi2008logic}{9}
\bibcite{piatetsky2003microarray}{10}
\bibcite{lommen2009metalign}{11}
\bibcite{holzinger2014knowledge}{12}
\bibcite{wilkins2009proteomics}{13}
\bibcite{teodoro2009biomedical}{14}
\bibcite{doi:10.1093/nar/gkm1037}{15}
\bibcite{sturn2002genesis}{16}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{26}{section.6}}
\newlabel{sec:Conclusions}{{6}{26}{Conclusions}{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{26}{section.7}}
\newlabel{sec:Discussion}{{7}{26}{Discussion}{section.7}{}}
\bibcite{karnovsky2011metscape}{17}
\bibcite{tabas2012genecodis3}{18}
\bibcite{faul2007g}{19}
\bibcite{dracopoli1991ceph}{20}
\bibcite{goldberg2008analysis}{21}
\bibcite{stibor2005negative}{22}
\bibcite{chandola2009anomaly}{23}
\bibcite{roberts2000extreme}{24}
\bibcite{donders2006gentle}{25}
\bibcite{cartwright2003dealing}{26}
\bibcite{haukoos2007advanced}{27}
\bibcite{kan1986short}{28}
\bibcite{diaconis1983computer}{29}
\bibcite{cestnikkononenkoj}{30}
\bibcite{murtaugh1994primary}{31}
\bibcite{fernandes2017transfer}{32}
\bibcite{patrician2002multiple}{33}
\bibcite{sterne2009multiple}{34}
\bibcite{myrtveit2001analyzing}{35}
\bibcite{pedersen2017missing}{36}
\bibcite{raghunathan2001multivariate}{37}
\bibcite{chevret2015multiple}{38}
\bibcite{rubin1976inference}{39}
\bibcite{white2011multiple}{40}
\bibcite{he2010multiple}{41}
\bibcite{van2007multiple}{42}
\bibcite{van1999multiple}{43}
\bibcite{van2006imputation}{44}
\bibcite{azur2011multiple}{45}
\bibcite{royston2004multiple}{46}
\bibcite{martin2018impact}{47}
\bibcite{horton2001multiple}{48}
\bibcite{allison2000multiple}{49}
\bibcite{royston2011multiple}{50}
\bibcite{pedregosa2011scikit}{51}
\bibcite{walt2011numpy}{52}
\bibcite{heiberger2004statistical}{53}
\bibcite{brown1974robust}{54}
\bibcite{satorra2001scaled}{55}
\bibcite{draper2014applied}{56}
\bibstyle{ieeetr}
\@writefile{toc}{\contentsline {section}{\numberline {A}Feature Distribution Tables}{29}{appendix.A}}
\newlabel{app:DistributionTables}{{A}{29}{Feature Distribution Tables}{appendix.A}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Testing for the cirrhosis dataset whether the type of missing values can be represented by the remaining values. This is done by comparing distributions between all sample values and remaining sample values after CCA and WCA. For nominal values, two tests were used, an independent t-test for equality of mean and a Levene's test with the median in brackets to test equality of variance. For ordinal and categorical features the medians and modes where checked respectively to be similar as well as a chi squared test in brackets fro equality of distribution. P-values lower than $p < 0.05$ are marked red for failure of representation, p-values higher than $p > 0.05$ are marked green for correctly being represented. If at least one feature is not represented after CCA, the missing values cannot be MCAR. If at least one feature is not represented after WCA, the pseudo-randomness cannot be corrected by only using weights for other values.\relax }}{30}{table.caption.20}}
\newlabel{tab:LDCirrhosis}{{10}{30}{Testing for the cirrhosis dataset whether the type of missing values can be represented by the remaining values. This is done by comparing distributions between all sample values and remaining sample values after CCA and WCA. For nominal values, two tests were used, an independent t-test for equality of mean and a Levene's test with the median in brackets to test equality of variance. For ordinal and categorical features the medians and modes where checked respectively to be similar as well as a chi squared test in brackets fro equality of distribution. P-values lower than $p < 0.05$ are marked red for failure of representation, p-values higher than $p > 0.05$ are marked green for correctly being represented. If at least one feature is not represented after CCA, the missing values cannot be MCAR. If at least one feature is not represented after WCA, the pseudo-randomness cannot be corrected by only using weights for other values.\relax }{table.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Testing for the cirrhosis data set if certain types of imputation create a vastly different distribution for features with missing values. The imputation values are generated with mean imputation, hot deck imputation, k-Nearest Neighbour imputation ($k = 3$), regression imputation and MICE (number of cycles is $s = 5$). For nominal values, two tests were used, an independent t-test for equality of mean and a Levene's test with the median in brackets to test equality of variance. For ordinal and categorical features the medians and modes where checked respectively to be similar as well as a chi squared test in brackets fro equality of distribution. P-values lower than $p < 0.05$ are marked red for failure of representation, p-values close to $p > 0.05$ are marked green for correctly being represented.\relax }}{31}{table.caption.21}}
\newlabel{tab:ImputationCirrhosis}{{11}{31}{Testing for the cirrhosis data set if certain types of imputation create a vastly different distribution for features with missing values. The imputation values are generated with mean imputation, hot deck imputation, k-Nearest Neighbour imputation ($k = 3$), regression imputation and MICE (number of cycles is $s = 5$). For nominal values, two tests were used, an independent t-test for equality of mean and a Levene's test with the median in brackets to test equality of variance. For ordinal and categorical features the medians and modes where checked respectively to be similar as well as a chi squared test in brackets fro equality of distribution. P-values lower than $p < 0.05$ are marked red for failure of representation, p-values close to $p > 0.05$ are marked green for correctly being represented.\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Classification Plots}{31}{appendix.B}}
\newlabel{app:ClassPlots}{{B}{31}{Classification Plots}{appendix.B}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A plot showing the accuracy for the Hepatitis dataset after using a missing value handling algorithm. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }}{32}{figure.caption.23}}
\newlabel{fig:EvalHepaAcc}{{9}{32}{A plot showing the accuracy for the Hepatitis dataset after using a missing value handling algorithm. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces A plot showing the accuracy for the Cirrhosis dataset after using a missing value handling algorithm. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }}{33}{figure.caption.24}}
\newlabel{fig:EvalCirrhAcc}{{10}{33}{A plot showing the accuracy for the Cirrhosis dataset after using a missing value handling algorithm. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A plot showing the accuracy for the Cervical cancer dataset after using a missing value handling algorithm. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }}{34}{figure.caption.25}}
\newlabel{fig:EvalCervhAcc}{{11}{34}{A plot showing the accuracy for the Cervical cancer dataset after using a missing value handling algorithm. The x-axis shows the computation time for the missing values, done on a 10-logarithmic scale due to the big differences between them. The y-axis shows the accuracy on a scale of 0 to 1. The explanation of every data point can be found both in the text on the top right of the data point as well as in the legend.\relax }{figure.caption.25}{}}
